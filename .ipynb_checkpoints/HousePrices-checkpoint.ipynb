{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Other\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data\n",
    "Read the data using pandas read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData  = pd.read_csv(\"data/test.csv\")\n",
    "trainData = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General workflow goals\n",
    "**Classifying** - We may want to classify or categorize our samples. We may also want to understand the implications or correlation of different classes with our solution goal.\n",
    "\n",
    "**Correlating** - One can approach the problem based on available features within the training dataset. Which features within the dataset contribute significantly to our solution goal? Statistically speaking is there a correlation among a feature and solution goal? As the feature values change does the solution state change as well, and visa-versa? This can be tested both for numerical and categorical features in the given dataset. We may also want to determine correlation among features other than survival for subsequent goals and workflow stages. Correlating certain features may help in creating, completing, or correcting features.\n",
    "\n",
    "**Converting** - For modeling stage, one needs to prepare the data. Depending on the choice of model algorithm one may require all features to be converted to numerical equivalent values. So for instance converting text categorical values to numeric values.\n",
    "\n",
    "**Completing** - Data preparation may also require us to estimate any missing values within a feature. Model algorithms may work best when there are no missing values.\n",
    "\n",
    "**Correcting** - We may also analyze the given training dataset for errors or possibly innacurate values within features and try to corrent these values or exclude the samples containing the errors. One way to do this is to detect any outliers among our samples or features. We may also completely discard a feature if it is not contribting to the analysis or may significantly skew the results.\n",
    "\n",
    "**Creating** - Can we create new features based on an existing feature or a set of features, such that the new feature follows the correlation, conversion, completeness goals.\n",
    "\n",
    "**Charting** - How to select the right visualization plots and charts depending on nature of the data and the solution goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial investigation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainData.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.describe(include=['O']) #Only include object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.describe(include=[np.number]) #Only include numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- PoolQC has only 7 entries\n",
    "- MiscFeature only has 54 entries\n",
    "- Alley has only 91 entires \n",
    "- Fence only has 281 entries \n",
    "- FireplaceQu only has 770 entries\n",
    "\n",
    "-> Guess this is because N/A has been selected\n",
    "\n",
    "- Mean sell price is 180'921 $\n",
    "- Most houses sold by middle of 2008\n",
    "- Mean LotArea is 10516.828082 sqFeet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifying** - See which features mostly correlates to sale price. Check early and compare with end result.\n",
    "\n",
    "**Correlating** - One can approach the problem based on available features within the training dataset. Which features within the dataset contribute significantly to our solution goal? Statistically speaking is there a correlation among a feature and solution goal? As the feature values change does the solution state change as well, and visa-versa? This can be tested both for numerical and categorical features in the given dataset. We may also want to determine correlation among features other than survival for subsequent goals and workflow stages. Correlating certain features may help in creating, completing, or correcting features.\n",
    "\n",
    "**Converting** - For modeling stage, one needs to prepare the data. Depending on the choice of model algorithm one may require all features to be converted to numerical equivalent values. So for instance converting text categorical values to numeric values.\n",
    "\n",
    "**Completing** - Data preparation may also require us to estimate any missing values within a feature. Model algorithms may work best when there are no missing values.\n",
    "\n",
    "**Correcting** - We may also analyze the given training dataset for errors or possibly innacurate values within features and try to corrent these values or exclude the samples containing the errors. One way to do this is to detect any outliers among our samples or features. We may also completely discard a feature if it is not contribting to the analysis or may significantly skew the results.\n",
    "\n",
    "**Creating** - Can we create new features based on an existing feature or a set of features, such that the new feature follows the correlation, conversion, completeness goals.\n",
    "\n",
    "**Charting** - How to select the right visualization plots and charts depending on nature of the data and the solution goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploritary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OverallQual vs SalePrice</th>\n",
       "      <td>0.790982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea vs SalePrice</th>\n",
       "      <td>0.708624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars vs SalePrice</th>\n",
       "      <td>0.640409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea vs SalePrice</th>\n",
       "      <td>0.623431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF vs SalePrice</th>\n",
       "      <td>0.613581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF vs SalePrice</th>\n",
       "      <td>0.605852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath vs SalePrice</th>\n",
       "      <td>0.560664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd vs SalePrice</th>\n",
       "      <td>0.533723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt vs SalePrice</th>\n",
       "      <td>0.522897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd vs SalePrice</th>\n",
       "      <td>0.507101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces vs SalePrice</th>\n",
       "      <td>0.466929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foundation vs SalePrice</th>\n",
       "      <td>-0.429678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeatingQC vs SalePrice</th>\n",
       "      <td>-0.427649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu vs SalePrice</th>\n",
       "      <td>0.402854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1 vs SalePrice</th>\n",
       "      <td>0.386420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF vs SalePrice</th>\n",
       "      <td>0.324413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF vs SalePrice</th>\n",
       "      <td>0.319334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF vs SalePrice</th>\n",
       "      <td>0.315856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1 vs SalePrice</th>\n",
       "      <td>-0.299343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath vs SalePrice</th>\n",
       "      <td>0.284108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotShape vs SalePrice</th>\n",
       "      <td>0.267759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExterQual vs SalePrice</th>\n",
       "      <td>-0.265015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea vs SalePrice</th>\n",
       "      <td>0.263843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CentralAir vs SalePrice</th>\n",
       "      <td>-0.251328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish vs SalePrice</th>\n",
       "      <td>0.247470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure vs SalePrice</th>\n",
       "      <td>0.244946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical vs SalePrice</th>\n",
       "      <td>-0.230830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath vs SalePrice</th>\n",
       "      <td>0.227122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF vs SalePrice</th>\n",
       "      <td>0.214479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PavedDrive vs SalePrice</th>\n",
       "      <td>-0.208954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea vs SalePrice</th>\n",
       "      <td>0.092404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandContour vs SalePrice</th>\n",
       "      <td>0.092009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass vs SalePrice</th>\n",
       "      <td>-0.084284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual vs SalePrice</th>\n",
       "      <td>0.083479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond vs SalePrice</th>\n",
       "      <td>-0.077856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaleType vs SalePrice</th>\n",
       "      <td>0.072896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature vs SalePrice</th>\n",
       "      <td>-0.061128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual vs SalePrice</th>\n",
       "      <td>0.058965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolQC vs SalePrice</th>\n",
       "      <td>0.051364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope vs SalePrice</th>\n",
       "      <td>0.051152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold vs SalePrice</th>\n",
       "      <td>0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition1 vs SalePrice</th>\n",
       "      <td>-0.044820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch vs SalePrice</th>\n",
       "      <td>0.044584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond vs SalePrice</th>\n",
       "      <td>0.041361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street vs SalePrice</th>\n",
       "      <td>-0.041036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoofMatl vs SalePrice</th>\n",
       "      <td>0.035820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType vs SalePrice</th>\n",
       "      <td>-0.031803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold vs SalePrice</th>\n",
       "      <td>-0.028923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF vs SalePrice</th>\n",
       "      <td>-0.025606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2 vs SalePrice</th>\n",
       "      <td>-0.023492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType vs SalePrice</th>\n",
       "      <td>-0.022405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond vs SalePrice</th>\n",
       "      <td>-0.021549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal vs SalePrice</th>\n",
       "      <td>-0.021190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath vs SalePrice</th>\n",
       "      <td>-0.016844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities vs SalePrice</th>\n",
       "      <td>-0.014314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2 vs SalePrice</th>\n",
       "      <td>-0.011378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition2 vs SalePrice</th>\n",
       "      <td>-0.004833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage vs SalePrice</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea vs SalePrice</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt vs SalePrice</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Value\n",
       "OverallQual vs SalePrice   0.790982\n",
       "GrLivArea vs SalePrice     0.708624\n",
       "GarageCars vs SalePrice    0.640409\n",
       "GarageArea vs SalePrice    0.623431\n",
       "TotalBsmtSF vs SalePrice   0.613581\n",
       "1stFlrSF vs SalePrice      0.605852\n",
       "FullBath vs SalePrice      0.560664\n",
       "TotRmsAbvGrd vs SalePrice  0.533723\n",
       "YearBuilt vs SalePrice     0.522897\n",
       "YearRemodAdd vs SalePrice  0.507101\n",
       "Fireplaces vs SalePrice    0.466929\n",
       "Foundation vs SalePrice   -0.429678\n",
       "HeatingQC vs SalePrice    -0.427649\n",
       "FireplaceQu vs SalePrice   0.402854\n",
       "BsmtFinSF1 vs SalePrice    0.386420\n",
       "WoodDeckSF vs SalePrice    0.324413\n",
       "2ndFlrSF vs SalePrice      0.319334\n",
       "OpenPorchSF vs SalePrice   0.315856\n",
       "BsmtFinType1 vs SalePrice -0.299343\n",
       "HalfBath vs SalePrice      0.284108\n",
       "LotShape vs SalePrice      0.267759\n",
       "ExterQual vs SalePrice    -0.265015\n",
       "LotArea vs SalePrice       0.263843\n",
       "CentralAir vs SalePrice   -0.251328\n",
       "GarageFinish vs SalePrice  0.247470\n",
       "BsmtExposure vs SalePrice  0.244946\n",
       "Electrical vs SalePrice   -0.230830\n",
       "BsmtFullBath vs SalePrice  0.227122\n",
       "BsmtUnfSF vs SalePrice     0.214479\n",
       "PavedDrive vs SalePrice   -0.208954\n",
       "...                             ...\n",
       "PoolArea vs SalePrice      0.092404\n",
       "LandContour vs SalePrice   0.092009\n",
       "MSSubClass vs SalePrice   -0.084284\n",
       "GarageQual vs SalePrice    0.083479\n",
       "OverallCond vs SalePrice  -0.077856\n",
       "SaleType vs SalePrice      0.072896\n",
       "MiscFeature vs SalePrice  -0.061128\n",
       "BsmtQual vs SalePrice      0.058965\n",
       "PoolQC vs SalePrice        0.051364\n",
       "LandSlope vs SalePrice     0.051152\n",
       "MoSold vs SalePrice        0.046432\n",
       "Condition1 vs SalePrice   -0.044820\n",
       "3SsnPorch vs SalePrice     0.044584\n",
       "GarageCond vs SalePrice    0.041361\n",
       "Street vs SalePrice       -0.041036\n",
       "RoofMatl vs SalePrice      0.035820\n",
       "GarageType vs SalePrice   -0.031803\n",
       "YrSold vs SalePrice       -0.028923\n",
       "LowQualFinSF vs SalePrice -0.025606\n",
       "BsmtFinType2 vs SalePrice -0.023492\n",
       "MasVnrType vs SalePrice   -0.022405\n",
       "BsmtCond vs SalePrice     -0.021549\n",
       "MiscVal vs SalePrice      -0.021190\n",
       "BsmtHalfBath vs SalePrice -0.016844\n",
       "Utilities vs SalePrice    -0.014314\n",
       "BsmtFinSF2 vs SalePrice   -0.011378\n",
       "Condition2 vs SalePrice   -0.004833\n",
       "LotFrontage vs SalePrice        NaN\n",
       "MasVnrArea vs SalePrice         NaN\n",
       "GarageYrBlt vs SalePrice        NaN\n",
       "\n",
       "[79 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "features = trainData.iloc[:,1:-1].columns.tolist()\n",
    "target = trainData.iloc[:,-1].name\n",
    "\n",
    "correlations = {}\n",
    "for f in features:\n",
    "    data_temp = trainData[[f,target]]\n",
    "    if data_temp[f].dtype == 'object':\n",
    "        data_temp[f] = pd.factorize(data_temp[f])[0] + 1\n",
    "    x1 = data_temp[f].values\n",
    "    x2 = data_temp[target].values\n",
    "    key = f + ' vs ' + target\n",
    "    correlations[key] = pearsonr(x1,x2)[0]\n",
    "\n",
    "data_correlations = pd.DataFrame(correlations, index=['Value']).T\n",
    "data_correlations.loc[data_correlations['Value'].abs().sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trainData.loc[:,['OverallQual ','GrLivArea',target]].sort_values(target, ascending=True).values\n",
    "x = np.arange(y.shape[0])\n",
    "\n",
    "%matplotlib inline\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(x,y[:,0])\n",
    "plt.title('Sqft and Grade vs Price')\n",
    "plt.ylabel('Sqft')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(x,y[:,1])\n",
    "plt.ylabel('Grade')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(x,y[:,2],'r')\n",
    "plt.ylabel(\"Price\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check the pivot of a perticular feature compared to sale price\n",
    "def checkPivot(data, feuature):\n",
    "    return data[[feuature, 'SalePrice']].groupby([feuature], as_index=False).mean().sort_values(by='SalePrice', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterFeatures = False\n",
    "\n",
    "#Check all categorical features to see which mostly correlates to a difference in sale price\n",
    "def var(feature):\n",
    "    data = checkPivot(trainData, feature)\n",
    "    maxPrize = data['SalePrice'].max()\n",
    "    minPrize = data['SalePrice'].min()\n",
    "    return maxPrize/minPrize\n",
    "\n",
    "varThreshold = 2\n",
    "\n",
    "catData = trainData.select_dtypes(include='object')\n",
    "featureList = [x for x in catData.columns]\n",
    "varDict = {}\n",
    "\n",
    "for f in featureList:\n",
    "    variance = var(f)\n",
    "    if not filterFeatures:\n",
    "        varThreshold = 0\n",
    "    if variance > varThreshold:\n",
    "        varDict[f] = variance\n",
    "\n",
    "importantFeatures = list(varDict)\n",
    "feat = OrderedDict(sorted(varDict.items(), key=lambda x: x[1], reverse=True))\n",
    "print(feat)\n",
    "print(importantFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing the pivot of the top 5 most corrolated features\n",
    "1. ExterQual\n",
    "2. Exterior1st\n",
    "3. Neighborhood\n",
    "4. Condition2\n",
    "5. BsmtCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check type of HouseStyle\n",
    "checkPivot(trainData, 'ExterQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check MSSubClass\n",
    "checkPivot(trainData, 'Exterior1st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Neighborhood\n",
    "checkPivot(trainData, 'Neighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pivit of having central ac vs not\n",
    "checkPivot(trainData, 'Condition2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pivit of having a good pool\n",
    "checkPivot(trainData, 'BsmtCond')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing continous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x=\"LotArea\", y=\"SalePrice\", data=trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  1979\n",
      "71\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-cf03f23e600a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misNull\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcolumnName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#trainData[].fillna( mean,inplace=True )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   9611\u001b[0m                                       skipna=skipna)\n\u001b[1;32m   9612\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[0;32m-> 9613\u001b[0;31m                             numeric_only=numeric_only)\n\u001b[0m\u001b[1;32m   9614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9615\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   3219\u001b[0m                                           'numeric_only.'.format(name))\n\u001b[1;32m   3220\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         return delegate._reduce(op=op, name=name, axis=axis, skipna=skipna,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mdtype_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# Remove NaN\n",
    "meanYr = math.ceil(trainData[\"GarageYrBlt\"].mean())\n",
    "print(\"Mean: \" , meanYr)\n",
    "\n",
    "for i,isNull in enumerate(trainData.isnull().any()):\n",
    "    if isNull:\n",
    "        columnName = trainData.columns[i]\n",
    "        mean = math.ceil(trainData.iloc[:,i].mean())\n",
    "        print(mean)\n",
    "        #trainData[].fillna( mean,inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre processing of data\n",
    "def processData(dataset, featureList, trainSize=0.8, isTraining=True, usePCA=False):\n",
    "    \n",
    "    # Replace null values\n",
    "    trainData[\"GarageYrBlt\"].fillna(meanYr,inplace=True)\n",
    "    \n",
    "    # Split up data set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(dataset[featureList], dataset[\"SalePrice\"], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convert to numerical values\n",
    "    for f in featureList:\n",
    "        X_train[f] = X_train[f].astype('category')\n",
    "        X_test[f]  = X_test[f].astype('category')\n",
    "    cat_columns = X_train.select_dtypes(['category']).columns\n",
    "    X_train[cat_columns] = X_train[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    X_test[cat_columns]  = X_test[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "    # Scale the data\n",
    "    X_train = StandardScaler().fit_transform(X_train)\n",
    "    X_test  = StandardScaler().fit_transform(X_test)\n",
    "    \n",
    "    # Return Principel components of data if desired\n",
    "    if usePCA:\n",
    "        pca = PCA(0.95)\n",
    "        pca.fit(X_train)\n",
    "\n",
    "        # Apply PCA\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "        \n",
    "        print(\"Components used for PCA: \", pca.n_components_)\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# # Use Principle Component Analysis\n",
    "# \n",
    "# \n",
    "# cpts = pd.DataFrame(pca.transform(X_train))\n",
    "\n",
    "# pcaList = pca.explained_variance_ratio_\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.set_xlabel('Pricipal components')\n",
    "# ax.set_ylabel('Percentage of variance')\n",
    "# ax.set_title('PCA', fontsize=20)\n",
    "\n",
    "# validPCAs = len(pcaList)\n",
    "# validPCAs = 20\n",
    "# bar_width = 0.35\n",
    "\n",
    "# index = np.arange(validPCAs)\n",
    "\n",
    "# ax.set_xticks(index + bar_width)\n",
    "# ax.set_xticklabels(index)\n",
    "\n",
    "# for i in range(validPCAs):\n",
    "#     ax.bar(i, pcaList[i], bar_width)\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# principalComp = pca.fit_transform(X_train)\n",
    "# PCdf = pd.DataFrame(data=principalComp, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestModel(X_train, Y_train):\n",
    "        \n",
    "    regr = RandomForestRegressor(oob_score=True, random_state=random_state, n_estimators=n_estimators)\n",
    "    regr.fit(X_train, Y_train)\n",
    "    \n",
    "    return regr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegressionModel(X_train, y_train):\n",
    "    \n",
    "    logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "    logisticRegr.fit(X_train, y_train)\n",
    "    \n",
    "    return logisticRegr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featureList = [\"ExterCond\", \"Functional\", \"BsmtCond\", \"GarageType\", \"Condition2\", \"GarageQual\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = processData(trainData, importantFeatures, isTraining = True)\n",
    "regr = randomForestModel(X_train, y_train)\n",
    "\n",
    "trainScore = round(regr.score(X_train, y_train) * 100, 2)\n",
    "testScore = round(regr.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "print(\"Train score: \", trainScore, \" Test Score: \", testScore)\n",
    "\n",
    "predicted_train = regr.predict(X_train)\n",
    "predicted_test = regr.predict(X_test)\n",
    "\n",
    "test_score = r2_score(y_test, predicted_test)\n",
    "spearman = spearmanr(y_test, predicted_test)\n",
    "pearson = pearsonr(y_test, predicted_test)\n",
    "\n",
    "print(f'Out-of-bag R-2 score estimate: {regr.oob_score_:>5.3}')\n",
    "print(f'Test data R-2 score: {test_score:>5.3}')\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}')\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = processData(trainData, importantFeatures, isTraining = True, usePCA=True)\n",
    "regr = logisticRegressionModel(X_train, y_train)\n",
    "\n",
    "trainScore = round(regr.score(X_train, y_train) * 100, 2)\n",
    "testScore = round(regr.score(X_test, y_test) * 100, 2)\n",
    "\n",
    "print(\"Train score: \", trainScore, \" Test Score: \", testScore)\n",
    "\n",
    "predicted_train = regr.predict(X_train)\n",
    "predicted_test = regr.predict(X_test)\n",
    "\n",
    "test_score = r2_score(y_test, predicted_test)\n",
    "spearman = spearmanr(y_test, predicted_test)\n",
    "pearson = pearsonr(y_test, predicted_test)\n",
    "\n",
    "print(f'Test data R-2 score: {test_score:>5.3}')\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}')\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance\n",
    "precision, recall, F1 Score, ROC Curve, etc would be better than simple score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
